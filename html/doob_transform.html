<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<link rel="Stylesheet" type="text/css" href="../config/notes.css">
<script type="text/javascript" src="../config/mathjax_local.js"></script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<!-- MathJax: Fall back to local if CDN offline -->
<script>window.MathJax || document.write('<script type="text/javascript" src="/usr/share/mathjax/MathJax.js?config=TeX-AMS_HTML-full"><\/script>')</script>

<title>Doob's \(h\)-transform</title>
<meta http-equiv="Content-Type" content="text/html; charset=%encoding%">
</head>
<body>
<div class="container">

<div class="left">
<ul><li><a href="about_tw.html">Welcome to toywiki</a></li><li><a href="cauchy_littlewood_identity.html">Cauchy-Littlewood identities</a></li><li>Doob's \(h\)-transform</li><li><a href="equivalence_m_rsk_md_lm_integrabilities.html">Equivalence between the Markov-Doob integrability and the local move integrability for usual-spec Macdonald RSK-type dynamics</a></li><li><a href="geometric_distribution.html">Geometric distributions</a></li><li><a href="local_move_integrability.html">Local move integrability</a></li><li><a href="macdonald_polynomials.html">Macdonald polynomials</a></li><li><a href="macdonald_polynomials_formula.html">Explicit formula of Macdonald polynomials</a></li><li><a href="macdonald_processes_measures.html">Macdonald processes and measures</a></li><li><a href="macdonald_rsk_local_move_integrability.html">Macdonald-RSK local move integrability</a></li><li><a href="macdonald_usual_markov_doob_integrability.html">Usual-spec Markov-Doob integrability for Macdonald processes</a></li><li><a href="markov_doob_integrability.html">Markov-Doob integrability</a></li><li><a href="markov_doob_integrability_triangular_array.html">Markov-Doob integrability on triangular arrays</a></li><li><a href="markov_function_theorem.html">Markov function theorem</a></li><li><a href="q_pochhammers.html">\(q\)-Pochhammers</a></li><li><a href="rsk_type_dynamics.html">RSK-type dynamics</a></li><li><a href="simple_symmetric_functions.html">Simple symmetric functions</a></li><li><a href="tw_people.html">toywiki people</a></li><li><a href="young_tableaux_gt_pattern.html">Young tableaux and Gelfand Tsetlin patterns</a></li></ul>
</div>

<div class="main">
<h1>Doob's \(h\)-transform</h1><hr/>


<p>
<span id="-doob_transform"></span><span class="tag" id="doob_transform">doob_transform</span>
</p>


<div id="Loosely speaking"><h2 id="Loosely speaking">Loosely speaking</h2></div>
<p>
Let \(A\) be a non-negative kernel on \(S\) and \(h\) that is \(A\)-harmonic positive function, then we call the transition kernel
</p>
\[
Q_h(x, y) = {h(y) \over h(x)} A(x, y),
\]
<p>
the Doob \(h\)-transform of \(A\).
</p>

<p>
<span id="Loosely speaking-Examples"></span><strong id="Examples">Examples</strong>:
</p>

<table>
<tr>
<th>
process
</th>
<th>
\(h\)
</th>
</tr>
<tr>
<td>
Schur processes
</td>
<td>
Schur functions
</td>
</tr>
<tr>
<td>
Whittaker processes
</td>
<td>
Whittaker functions
</td>
</tr>
<tr>
<td>
\(q\)-Whittaker processes
</td>
<td>
\(q\)-Whittaker functions
</td>
</tr>
<tr>
<td>
Macdonald processes
</td>
<td>
Macdonald polynomials
</td>
</tr>
</table>

<p>
In <a href="markov_doob_integrability.html">Markov doob integrability</a> and the notes that depend on it we use this "loosely speaking" version of Doob's \(h\)-transform.
</p>

<p>
In the following we mostly follow exposition in Bloemendal's draft notes "Doob's \(h\)-transform: theory and examples".
</p>
<div id="Derivation"><h2 id="Derivation">Derivation</h2></div>
<p>
Consider a (continuous or discrete time) Markov process \(X_t\) on state \(S\) with kernel \(P_t\).
We associate with it a path space \(\Omega\) with probability measures \((P_x)_{x \in S}\), and let \(\mcf_t\) be the natural filtration of \((X_t)\).
</p>

<p>
Let 
</p>
\[
\mci := \{A: \theta_t^{-1} A = A \forall t\ge 0\},
\]
<p>
then any \(\mci\)-measurable function is shift-invariant: \(H \circ \theta_t = H \forall t \ge 0\), since
</p>
\[
(H \circ \theta_t)^{-1} B = \theta_t^{-1} H^{-1} (B).
\]

<p>
<span id="Derivation-Claim 1"></span><strong id="Claim 1">Claim 1</strong>. There is a one-one correspondence between bounded \(\mci\)-measurable functions and bounded \(P_t\)-harmonic functions.
</p>

<p>
<span id="Derivation-Proof"></span><strong id="Proof">Proof</strong>. For any \(H \in \mci\), let
</p>
\[
h(x) = \expe_x H
\]
<p>
Then by the Markov property
</p>
\[
h(X_t) = \expe_{X_t} H = \expe_x (H \circ \theta_t | \mcf_t) = \expe_x (H | \mcf_t)
\]
<p>
is a 
martingale, hence by Corollary 4 in infinitesimal_generator \(h\) is \(P_t\)-harmonic.
</p>

<p>
Conversely, given \(P_t\)-harmonic \(h\), by martingale convergence theorem
</p>
\[
H = \lim_{t \to \infty} h(X_t)
\]
<p>
exists. And obviously \(H \in \mci\). \(\square\)
</p>

<p>
\(L^\infty \mci\) is called the Poisson boundary.
</p>

<p>
For \(H = \ind_A\) for some \(A \in \mci\), we define the conditional probability \(Q_x = P_x(\cdot | A)\) (see Claim 1 in radon_nikodym_derivative)
</p>
\[
{d Q_x \over d P_x} = {\ind_A \over h(x)}.
\]

<p>
By <span id="Derivation-Claim 2"></span><strong id="Claim 2">Claim 2</strong> in radon_nikodym_derivative and Pf of Claim 1
</p>
\[
{d Q_x \over d P_x}|_{\mcf_t} = {h(X_t) \over h(x)}
\]

<p>
Let \(\tilde S = \{x \in S: h(x) &gt; 0\}\) be accessible states. 
</p>

<p>
<span id="Derivation-Claim"></span><strong id="Claim">Claim</strong>. \(Q_x\) is a probability measure on paths in \(\tilde S\) 
</p>

<p>
<span id="Derivation-Proof"></span><strong id="Proof">Proof</strong>. \(\forall t\), \(Q_x (h(X_t) &gt; 0) = \expe_x \ind_{h (X_t) &gt; 0} {h (X_t) \over h(x)} = \expe_x {h(X_t) \over h(x)} = 1\), thus \(\forall t X_t \in \tilde S, P_x\)-a.s. 
\(\square\)
</p>

<p>
Define kernel \(Q_t\)
</p>
\[
Q_t(x, d y) = {h(y) \over h(x)} P_t(x, dy) \qquad (1)
\]

<p>
<span id="Derivation-Claim"></span><strong id="Claim">Claim</strong>. \(Q_t\) is a stochastic semigroup.
</p>

<p>
<span id="Derivation-Proof"></span><strong id="Proof">Proof</strong>.
</p>
<ul>
<li>
\(Q_t\) is stochastic because \(h\) is \(P_t\)-harmonic.

<li>
\(Q_t\) is a semigroup because it is a conjugate of \(P_t\)

</ul>
<p>
\(\square\)
</p>

<p>
<span id="Derivation-Theorem 1"></span><strong id="Theorem 1">Theorem 1</strong>. Under \(Q_x\) with \(x \in \tilde S\), \(X_t\) is Markov on \(\tilde S\) with kernel \(Q_t\)
</p>

<p>
<span id="Derivation-Proof"></span><strong id="Proof">Proof</strong>. Formally using Bayes theorem
</p>
\[
P_x(X_{t + s} \in dy | A, \mcf_t) = {P_x(A | X_{t + s} = y, \mcf_t) P_x(X_{t + s} \in dy | \mcf_t) \over P_x(A | \mcf_t)} = {\expe_y(\ind_A \circ \theta_{t + s}) P_{X_t}(X_{t + s} \in dy) \over \expe_x (\ind_A | \mcf_t)} = {h(y) P_s(X_t, dy) \over h(X_t)}.
\]
<p>
More precisely we want to show
</p>
\[
\expe^Q_x (f(X_{t + s}) | \mcf_t) = h(X_t)^{-1} \expe_{X_t} f(X_s) h(X_s) \qquad Q_x \text{-a.s.}
\]
<p>
We start from the RHS. For \(B \in \mcf_t\),
</p>
\begin{align}
\expe_x^Q &amp;h(X_t)^{-1} \expe_{X_t} f(X_s) h(X_s) \ind_B \\
&amp;= \expe^Q_x h(X_t)^{-1} \expe_x(f(X_{t + s}) h(X_{t + s}) | \mcf_t) \ind_B\\
&amp;= \expe_x {h(X_t) \over h(x)} h(X_t)^{-1} \expe_x(f(X_{t + s}) h(X_{t + s}) | \mcf_t) \ind_B\\
&amp;= \expe_x h(x)^{-1} f(X_{t + s}) h(X_{t + s}) \ind_B\\
&amp;= \expe^Q_x f(X_{t + s}) \ind_B
\end{align}
<p>
\(\square\).
</p>

<div id="Continuous-time"><h2 id="Continuous-time">Continuous-time</h2></div>
<p>
Taking generator on both sides of (1) we have
</p>
\[
L^Q = m_{1 / h} L^P m_h \qquad (1.5)
\]

<p>
<span id="Continuous-time-Claim"></span><strong id="Claim">Claim</strong>. Specifically if \(X\) is a diffusion under \(P\) with SDE and generator
</p>
\begin{align}
d X_t &amp;= \sigma(X_t) d B_t + b(X_t) dt\\
L^P &amp;= {1 \over 2} \sigma \sigma^T : \nabla \nabla^T + b \cdot \nabla = {1 \over 2} \sum a_{i j} \partial_{x_i x_j} + \sum b_i \partial_{x_i} (1.7)
\end{align}
<p>
then
</p>
\[
L^Q = L^P + a \nabla \log h \cdot \qquad (2)
\]

<p>
<span id="Continuous-time-Proof"></span><strong id="Proof">Proof</strong>. plug \(L^P\) in (1.7) into (1.5), and noting \(L h = 0\). \(\square\)
</p>

<p>
<span id="Continuous-time-Remark"></span><strong id="Remark">Remark</strong>. (2) can also be written as
</p>
\[
L^Q f = L^P f + {1 \over h} \sigma^T \nabla h \cdot \sigma^T \nabla f
\]

<p>
We also have that under \(Q\),
</p>
\[
d X_t = \sigma(X_t) d B_t + (b(X_t) + a \nabla h(X_t)) dt
\]
<p>
namely a drift in the direction of increasing \(h\) is added.
</p>

<div id="Conditioning on a null event"><h2 id="Conditioning on a null event">Conditioning on a null event</h2></div>
<p>
When \(P_x(A) = 0 \forall x\), one has to resort to the theory of Martin boundary (see perhaps e.g. [{sawyer97}]).
</p>

<p>
Heuristically, one may use a sequence \(A_n \in \mci\) (with harmonic function \(h_n\)) such that \(\bigcup A_n = A\), and a sequence \(c_n \in \real\) such that \(\lim_n c_n h_n = h\) exists, is finite and positive.
</p>

<div id="Absorbing boundary"><h2 id="Absorbing boundary">Absorbing boundary</h2></div>
<p>
A special case is when we consider an absorbing boundary \(\partial S \subset S\) such that
</p>
\[
P_t(x, dy) = \delta_x(dy), \forall x \in \partial S \forall t \ge 0
\]
<p>
is the delta measure.
</p>

<p>
Let \(T = \tau_{\partial S}\), the previous formula means \(X_t = X_{t \wedge T}\).
</p>

<p>
We also consider \(Z \subset \partial S\), and \(H = \{X_T \in Z\}\).
</p>

<p>
Then the condition is "the Markov process hits \(Z\) when exitting \(S \setminus \partial S\)", i.e. \(\{X_T \in Z\}\).
</p>

<p>
The harmonic function \(h\) is then a solution to the Dirichlet problem:
</p>
\[
\begin{cases}
L h(x) = 0, \qquad x \in S \setminus \partial S\\
h(x) = \ind_Z, \qquad x \in \partial S
\end{cases}
\]

<p>
The solution 
</p>
\[
$h(x) = P_x(X_T \in Z) = \expe_x h(X_T)
\]
<p>
is a special case of potential theory in probability:
</p>
\[
\begin{cases}
L h(x) = 0, \qquad x \in S \setminus \partial S\\
h(x) = f(x), \qquad x \in \partial S.
\end{cases}
\]
<p>
has solution
</p>
\[
u(x) = \expe_x f(X_T)
\]
<p>
since \(u(X_t)\) is a martingale since
</p>
\[
u(X_t) = \expe_{X_t} f(X_T) = \expe(f(X_{T + t}) | \mcf_t) = \expe(f(X_T) | \mcf_t)
\]
<p>
due to the absorbing boundary.
</p>
<div id="Examples"><h2 id="Examples">Examples</h2></div>
<div id="Examples-Simple random walk on $0 : N$ hitting $N$ before $0$."><h3 id="Simple random walk on $0 : N$ hitting $N$ before $0$.">Simple random walk on \(0 : N\) hitting \(N\) before \(0\).</h3></div>
<p>
\(S = 0 : N\), \(\partial S = \{0, N\}\), \(Z = \{N\}\).
</p>

<p>
If \(X_t\) is symmetric then the equation \(P h = h\) is
</p>
\[
h(i) = {1 \over 2} (h(i + 1) + h(i - 1)), \qquad i = 1 : N - 1 \qquad (3)
\]

<p>
combined with boundary condition it is a Dirichlet problem for Laplace equation:
</p>
\[
\begin{cases}
\Delta h(i) = 0, \qquad i = 1 : N - 1\\
h(0) = 0\\
h(N) = 1
\end{cases}
\]
<p>
where \(\Delta\) is the discrete Laplacian.
</p>

<p>
Solving this equation gives
</p>
\[
h(i) = i / N
\]
<p>
and the kernel \(Q\) of the conditioned process by (1) is
</p>
\[
Q(i, i + 1) = {i + 1 \over 2 i},\qquad Q(i, i - 1) = {i - 1 \over 2 i}, \qquad Q(i, \text{other j}) = 0 \qquad (4)
\]

<p>
If \(X_t\) is asymmetric, with probability \(p\) of jumping from \(i\) to \(i + 1\), then the equation (3) is now
</p>
\[
h(x) = p h(x + 1) + (1 - p) h(x - 1)
\]
<p>
with the same boundary condition.
Solving it gives
</p>
\[
h(i) = {1 - r^i \over 1 - r^N}
\]
<p>
where \(r = {1 - p \over p}\).
</p>

<div id="Examples-Brownian motion on $[0, M]$ hitting $M$ before $0$"><h3 id="Brownian motion on $[0, M]$ hitting $M$ before $0$">Brownian motion on \([0, M]\) hitting \(M\) before \(0\)</h3></div>
<p>
Same as in the RW example, but continuous time.
</p>

<p>
\(S = [0, M]\), \(\partial S = \{0, M\}\), \(Z = \{M\}\).
</p>

<p>
The equation \(L h = 0\) with boundary condition is a Dirichlet problem
</p>
\[
\begin{cases}
{1 \over 2} h_{xx} (x) = 0 \qquad x \in (0, M)\\
h(0) = 0\\
h(M) = 1
\end{cases}
\]
<p>
solving which gives
</p>
\[
h(x) = x / M.
\]

<p>
Hence by (2) we have
</p>
\[
L^Q = {1 \over 2} \partial_{xx} + {1 \over x} \partial_x.
\]

<div id="Examples-Brownian motion on $[0, \pi]$ conditioned to remain in $(0, \pi)$ up to time $t_1$"><h3 id="Brownian motion on $[0, \pi]$ conditioned to remain in $(0, \pi)$ up to time $t_1$">Brownian motion on \([0, \pi]\) conditioned to remain in \((0, \pi)\) up to time \(t_1\)</h3></div>
<p>
We use the space-time trick.
\(S = [0, t_1] \times [0, \pi]\), \(\partial S = [0, t) \times \{0, \pi\} \cup \{t_1\} \times [0, \pi]\), \(Z = \{t_1\} \times [0, \pi]\).
</p>

<p>
Since the generator of \((t, X_t)\) is \(\hat L = \partial_t + L\), combining this with boundary condition we obtain the backward heat equation:
</p>
\[
\begin{cases}
 \partial_t \hat h + {1 \over 2} \partial_{xx} \hat h = 0, \qquad (x, t) \in [0, t_1) \times (0, \pi) \\
 h(t, 0) = h(t, \pi) = 0\qquad t \in [0, t_1)\\
 h(t_1, x) = 1 \qquad x \in [0, \pi]
\end{cases}
\]

<p>
Solving this equation we have
</p>
\[
\hat h(t, x) = \sum_{k \ge 1} c_k e^{- k^2 (t_1 - t)} \sin(k x)
\]
<p>
where \(c_k = {4 \over k \pi} \ind_{2 \nmid k}\).
</p>

<p>
So the new generator is
</p>
\[
\hat L^Q = \partial_t + L + {\partial_{t, x} \hat h(x, t) \over \hat h(x, t)} \cdot \nabla_{t, x} = \partial_t + L + {\sum c_k k e^{-k^2(t_1 - t)} \cos(k x) \over \sum c_k e^{- k^2 (t_1 - t)} \sin(k x)} \partial_x + {\sum c_k e^{- k^2 (t_1 - t)} (- k^2) \sin k x \over \sum c_k e^{- k^2 (t_1 - t)} \sin k x} \partial_t.
\]


<p>
Other examples include Bessel processes, dyson_brownian_motion, brownian_bridge, brownian_excursion, and various RS(K)-related models.
</p>
<div id="Discrete case (possibly Martin boundary)"><h2 id="Discrete case (possibly Martin boundary)">Discrete case (possibly Martin boundary)</h2></div>
<p>
This section follows exposition in [{oconnell03a}], let \(P\) be a substochastic transition matrix on a countably infinite state sapce \(S\),
and \(G\) to be the associated Green's function:
</p>
\[
G(x, y) = \sum_{n \ge 0} P^n (x, y).
\]
<p>
Assuming 
\(\exists x^* \in S\) s.t. \(0 &lt; G(x^*, y) &lt; \infty \forall y \in S\).
Suppose \(h\) is a positive harmonic function w.r.t. \(P\), then the Doob \(h\)-transform of \(P\) is the stochastic kernel \(P_h\) defined by
</p>
\[
P_h(x, y) = {h(y) \over h(x)} P(x, y).
\]

<p>
<span id="Discrete case (possibly Martin boundary)-Theorem"></span><strong id="Theorem">Theorem</strong> (Doob). If \(\exists f\) s.t.
</p>
\[
\lim_{n \to \infty} {G(x, X(n)) \over G(x^*, X(n))} = f(x) \qquad a.s.
\]
<p>
then \(h = C f\) for some \(C\).
</p>

<p>
When conditioning on an event \(B\) with positive probability, we take
</p>
\[
h(x) = P_x(B).
\]

<p>
<span id="Discrete case (possibly Martin boundary)-Remark"></span><strong id="Remark">Remark</strong>. The continuous case should be defined similarly.
</p>

<p>
<span id="Discrete case (possibly Martin boundary)-Remark"></span><strong id="Remark">Remark</strong>. Conditioning on a null event is more tricky. I know some examples, but don't know how the \(h\)'s are chosen.
</p>


<h2>References</h2><ul>
<li>
[oconnell03a] <span class="title">Conditioned random walks and the RSK correspondence</span>, <span class="author">N. O'Connell</span>, <i>Journal of Physics A: Mathematical and General</i>, Vol. 36, No. 12, p.3049&ndash;3066, March<span class="year"> 2003</span>.</li>

<li>
[sawyer97] <span class="title">Martin boundaries and random walks</span>, <span class="author">Stanley A Sawyer</span>, <i>Contemporary Mathematics</i>, Vol. 206, p.17&ndash;44<span class="year"> 1997</span>.</li>
</ul>
</div>

<div class="clear"></div>

<div class="footer">
    <hr/>
    <div class="footerleft">
        <a href="about_tw.html">about</a>. <a href="https://github.com/ycpei/toywiki">toywiki on Github</a>. <a href="tw_people.html">people</a>. contact: &#109;&#101;&#64;&#121;&#112;&#101;&#105;&#46;&#109;&#101;
    </div>
    <div class="footerright">
        Last updated on 25 Apr 2017. <!--views-->
        Licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC-BY-SA 4.0</a>
    </div>
</div>

</div>

</body>
</html>
