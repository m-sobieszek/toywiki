<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<link rel="Stylesheet" type="text/css" href="../config/notes.css">

<script type="text/javascript" src="../config/mathjax_local.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.11.0/styles/googlecode.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.11.0/highlight.min.js"></script>
<script type="text/javascript" src="../config/highlightconfig.js"></script>
<!-- MathJax: Fall back to local if CDN offline -->
<!--<script>window.MathJax || document.write('<script type="text/javascript" src="/usr/share/mathjax/MathJax.js?config=TeX-AMS_HTML-full"><\/script>')</script>-->

<title>Markov function theorem</title>
<meta http-equiv="Content-Type" content="text/html; charset=%encoding%">
</head>
<body>
<div class="container">

<div class="left">
<ul><li><a href="about_tw.html">Welcome to toywiki</a></li><li><a href="cauchy_littlewood_identity.html">Cauchy-Littlewood identities</a></li><li><a href="doob_transform.html">Doob's \(h\)-transform</a></li><li><a href="equivalence_m_rsk_md_lm_integrabilities.html">Equivalence between the Markov-Doob integrability and the local move integrability for usual-spec Macdonald RSK-type dynamics</a></li><li><a href="geometric_distribution.html">Geometric distributions</a></li><li><a href="local_move_integrability.html">Local move integrability</a></li><li><a href="macdonald_polynomials.html">Macdonald polynomials</a></li><li><a href="macdonald_polynomials_formula.html">Explicit formula of Macdonald polynomials</a></li><li><a href="macdonald_processes_measures.html">Macdonald processes and measures</a></li><li><a href="macdonald_rsk_local_move_integrability.html">Macdonald-RSK local move integrability</a></li><li><a href="macdonald_usual_markov_doob_integrability.html">Usual-spec Markov-Doob integrability for Macdonald processes</a></li><li><a href="markov_doob_dynamics_triangular_array.html">Markov-Doob integrable dynamics on triangular arrays</a></li><li><a href="markov_doob_integrability.html">Markov-Doob integrability</a></li><li><a href="markov_doob_integrability_triangular_array.html">Markov-Doob integrability on triangular arrays</a></li><li>Markov function theorem</li><li><a href="pitman_transform_type_a.html">Pitman's transform of type A</a></li><li><a href="q_pochhammers.html">\(q\)-Pochhammers</a></li><li><a href="robinson_schensted.html">Robinson-Schensted algorithm</a></li><li><a href="robinson_schensted_knuth.html">Robinson-Schensted-Knuth algorithms</a></li><li><a href="rs_pitman_type_a.html">RS algorithms as type-A Pitman's transforms</a></li><li><a href="rsk_path_transformation.html">RSK algorithms as path transformations</a></li><li><a href="rsk_type_dynamics.html">RSK-type dynamics</a></li><li><a href="simple_symmetric_functions.html">Simple symmetric functions</a></li><li><a href="tw_people.html">toywiki people</a></li><li><a href="young_tableaux_gt_pattern.html">Young tableaux and Gelfand-Tsetlin patterns</a></li></ul>
</div>

<div class="main">
<h1>Markov function theorem</h1><hr/>


<p>
<span id="-markov_function_theorem"></span><span class="tag" id="markov_function_theorem">markov_function_theorem</span> <span id="-intertwining_relation"></span><span class="tag" id="intertwining_relation">intertwining_relation</span>
</p>


<p>
The Markov function theorem can be found in [{rogers-pitman81}].
</p>

<div id="Definitions and proof"><h2 id="Definitions and proof">Definitions and proof</h2></div>
<p>
<span id="Definitions and proof-Theorem"></span><strong id="Theorem">Theorem</strong>(discrete time discrete space version of Markov function theorem). Let \(X\) be a Markov process with transition kernel \(P\) on state space \(S\), \(f : S \to T\) for some space \(T\), and \(Y\) a process on space \(T\) defined by \(Y_t = f(X_t)\) for some \(f\). 
If there is a kernel \(K: T \times S \to [0, 1]\) such that 
</p>

<ol>
<li>
\(K(y, x) = 0 \forall x \notin f^{-1}(y)\)

<li>
\(\sum_{x \in S} K(y, x) = 1 \forall y \in T\). 

</ol>

<p>
Then if stochastic matrix \(Q: T \times T \to [0,1]\) satisfies the intertwining relation
</p>
\[
 Q K = K P \qquad (1)
\]
<p>
then if \(X_0 \sim K(Y_0, \cdot)\) then 
</p>
<ul>
<li>
\(Y\) evolves as a Markov chain with kernel \(Q\).

<li>
\(\prob(X_n = x|Y_n = y, Y_{n - 1}, ..., Y_0) = K(y, x)\).

</ul>

<p>
<span id="Definitions and proof-Remark"></span><strong id="Remark">Remark</strong>. Condition 1 means \((K(y, \cdot))_y\) has disjoint supports \(f^{-1}(y)\). Therefore the LHS of of (1) has only one term and (1) becomes
</p>
\[
Q(y, f(x')) K(f(x'), x') = \sum_{x \in f^{-1}(y)} K(y, x) P(x, x').
\]
<p>
The intertwining relation (1) is the most important part of the theorem.
Once it is verified, the results of the theorem should follow.
</p>

<p>
<span id="Definitions and proof-Proof"></span><strong id="Proof">Proof</strong>. Let \(y_{0: n} \subset T\). Denote \(A_k := f^{- 1} (y_k)\).
</p>
\begin{align}
 \mathbb P_{Y_0 = y_0} (Y_{0: n} = y_{0: n}) &amp;= \mathbb P_{X_0 \sim K(y_0, \cdot)} (X_0 \in A_0, X_1 \in A_1, ..., X_n \in A_n) \\
&amp;= \sum_{x_{0: n} \in A_{0: n}} K(y_0, x_0) P(x_0, x_1) P(x_1, x_2) ... P(x_{n - 1}, x_n)\\
&amp;= \sum_{y_1' \in T, x_{1: n} \in A_{1: n}} Q(y_0, y_1') K(y_1', x_1) P(x_1, x_2) ... P(x_{n - 1}, x_n) \\
&amp;\overset{\dagger}{=} \sum_{x_{1: n} \in A_{1: n}} Q(y_0, y_1) K(y_1, x_1) P(x_1, x_2) ... P(x_{n - 1}, x_n)\\
&amp;= ... = \sum_{x_n \in A_n} Q(y_0, y_1) Q(y_1, y_2) ... Q(y_{n - 1}, y_n) K(y_n, x_n) \\
&amp;\overset{\dagger\dagger}{=} Q(y_0, y_1) Q(y_1, y_2) ... Q(y_{n - 1}, y_n).
\end{align}
<p>
where \(\dagger\) and \(\dagger\dagger\) we use the first and second conditions respectively.
Therefore \(Y\) is a Markov process with transition kernel \(Q\). The proof for the continuous case should be the same.  \(\square\)
</p>

<p>
Both assumptions that \(X\) and \(Y\) are probabilistic, as well as the positivity of \(K\) can be relaxed, if we only focus on the algebraic structure.
</p>


<p>
For continuous-time Markov processes / chains besides the transition kernel there are also generators, and we have a corresponding version of the Markov function theorem as well.
</p>

<p>
<span id="Definitions and proof-Theorem"></span><strong id="Theorem">Theorem</strong>(continuous-time version of the Markov function theorem). Let \(X\) be a Markov process with generator \(L^X\) on space \(S\), and \(Y\) a process on \(T\) where \(Y_t = f(X_t)\) for some \(f\). If there is a kernel \(K: T \times S \to [0, 1]\) such that 
</p>
<ol>
<li>
\(K(y, x) = 0 \forall x \notin f^{-1}(y)\) 

<li>
\(\int K(y, x) dx = 1\) for all \(y \in T\) 

</ol>
<p>
Then if Markov generator \(L^Y\) satisfies the intertwining relation
</p>
\[
 K L^X = L^Y K
\]
<p>
then \(Y\) is Markov with generator \(L^Y\).
</p>

<div id="Relation between the continuous and discrete Markov chain versions"><h2 id="Relation between the continuous and discrete Markov chain versions">Relation between the continuous and discrete Markov chain versions</h2></div>
<p>
This bit is not verified by many examples. But just the RSK.
</p>

<p>
Suppose we have continuous-time Markov chains \(\hat X\) and \(\hat Y\) with generator \(\hat P\) and \(\hat Q\), and their embedded discrete-time chains \(X\) and \(Y\) with transition matrices \(P\) and \(Q\), such that
</p>
\[
 P(x, x') = \begin{cases}
- {\hat P(x, x') \over \hat P(x, x)}, &amp; x \neq x' \\
0, &amp;x = x'
\end{cases};\qquad
Q(x, x') = \begin{cases}
- {\hat Q(x, x') \over \hat Q(x, x)}, &amp; x \neq x' \\
0, &amp;x = x'
\end{cases}
\]

<p>
In one case we can say that \(P\) and \(Q\) intertwines with \(K\) iff \(\hat P\) and \(\hat Q\) with the same kernel.
</p>

<p>
<span id="Relation between the continuous and discrete Markov chain versions-Claim"></span><strong id="Claim">Claim</strong>. Assuming the following is satisfied:
</p>
<ol>
<li>
\(\hat P(x, x) = \hat Q(y, y) = c \forall x, y\)

<li>
\(\hat P(x, x') = 0\) whenever \(f(x) = f(x')\) and \(x \neq x'\),

</ol>
<p>
then
</p>
\[
 \hat Q K = K \hat P \Leftrightarrow Q K = K P.
\]

<p>
<span id="Relation between the continuous and discrete Markov chain versions-Proof"></span><strong id="Proof">Proof</strong>. Quite straightforward. Consider the cases \(y = y'\) and \(y \neq y'\) separately. \(\square\)
</p>

<p>
This Claim allows us to verify the intertwining relations of the embedded chains. One example are the RS models, where the continuous-time version has an input of \(\ell\) Poisson processes, and \(X, Y\) are two levels of shapes \((\lambda^{\ell - 1}, \lambda^\ell), \lambda^\ell\). 
The two conditions correspond to
</p>
<ol>
<li>
The total rate of change of \(X\) and \(Y\) are the sum of rates of the input Poisson processes

<li>
Whenever \(\lambda^{\ell - 1}\) changes the next level changes as well

</ol>


<h2>References</h2><ul>
<li>
[rogers-pitman81] <span class="title">Markov functions</span>, <span class="author">L.C.G. Rogers, J.W. Pitman</span>, <i>Annals of Probability</i>, Vol. 9, No. 4, p.573&ndash;582<span class="year"> 1981</span>.</li>
</ul>
</div>

<div class="clear"></div>

<div class="footer">
    <hr/>
    <div class="footerleft">
        <a href="about_tw.html">about</a>. <a href="https://github.com/ycpei/toywiki">toywiki on Github</a>. <a href="tw_people.html">people</a>. contact: &#109;&#101;&#64;&#121;&#112;&#101;&#105;&#46;&#109;&#101;
    </div>
    <div class="footerright">
        Last updated on 16 May 2017. <!--views-->
        Licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>
    </div>
</div>

</div>

</body>
</html>
